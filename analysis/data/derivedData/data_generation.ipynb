{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare Data\n",
    "\n",
    "Source: https://chronicdata.cdc.gov/500-Cities-Places/500-Cities-Census-Tract-level-Data-GIS-Friendly-Fo/k86t-wghb/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "health_data = pd.read_csv(\"500_Cities__Census_Tract-level_Data__GIS_Friendly_Format___2019_release_20250317.csv\", dtype=str)\n",
    "health_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Socio-economic Data\n",
    "\n",
    "source: https://www.census.gov/data/developers/data-sets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for state 01...\n",
      "Fetching data for state 02...\n",
      "Fetching data for state 04...\n",
      "Fetching data for state 05...\n",
      "Fetching data for state 06...\n",
      "Fetching data for state 08...\n",
      "Fetching data for state 09...\n",
      "Fetching data for state 10...\n",
      "Fetching data for state 11...\n",
      "Fetching data for state 12...\n",
      "Fetching data for state 13...\n",
      "Fetching data for state 15...\n",
      "Fetching data for state 16...\n",
      "Fetching data for state 17...\n",
      "Fetching data for state 18...\n",
      "Fetching data for state 19...\n",
      "Fetching data for state 20...\n",
      "Fetching data for state 21...\n",
      "Fetching data for state 22...\n",
      "Fetching data for state 23...\n",
      "Fetching data for state 24...\n",
      "Fetching data for state 25...\n",
      "Fetching data for state 26...\n",
      "Fetching data for state 27...\n",
      "Fetching data for state 28...\n",
      "Fetching data for state 29...\n",
      "Fetching data for state 30...\n",
      "Fetching data for state 31...\n",
      "Fetching data for state 32...\n",
      "Fetching data for state 33...\n",
      "Fetching data for state 34...\n",
      "Fetching data for state 35...\n",
      "Fetching data for state 36...\n",
      "Fetching data for state 37...\n",
      "Fetching data for state 38...\n",
      "Fetching data for state 39...\n",
      "Fetching data for state 40...\n",
      "Fetching data for state 41...\n",
      "Fetching data for state 42...\n",
      "Fetching data for state 44...\n",
      "Fetching data for state 45...\n",
      "Fetching data for state 46...\n",
      "Fetching data for state 47...\n",
      "Fetching data for state 48...\n",
      "Fetching data for state 49...\n",
      "Fetching data for state 50...\n",
      "Fetching data for state 51...\n",
      "Fetching data for state 53...\n",
      "Fetching data for state 54...\n",
      "Fetching data for state 55...\n",
      "Fetching data for state 56...\n",
      "                                      Geography  Total_Households   \n",
      "0     Census Tract 201, Autauga County, Alabama               609  \\\n",
      "1     Census Tract 202, Autauga County, Alabama               600   \n",
      "2     Census Tract 203, Autauga County, Alabama              1346   \n",
      "3     Census Tract 204, Autauga County, Alabama              1606   \n",
      "4  Census Tract 205.01, Autauga County, Alabama              1789   \n",
      "\n",
      "   Total_Population  Median_Household_Income  Poverty_Population   \n",
      "0              1791                    57399                 275  \\\n",
      "1              2010                    52176                 117   \n",
      "2              3577                    63704                 614   \n",
      "3              3802                    70000                 307   \n",
      "4              4381                    60917                 790   \n",
      "\n",
      "   Unemployed_Population  Per_Capita_Income  SNAP_Recipients   \n",
      "0                     19            30934.0              129  \\\n",
      "1                     43            26446.0              121   \n",
      "2                     45            25683.0              166   \n",
      "3                     40            47804.0               39   \n",
      "4                     25            30313.0              160   \n",
      "\n",
      "   Total_Pop_Health_Insurance  Uninsured_Population  ...  Elderly_Population   \n",
      "0                        1791                     0  ...                  14  \\\n",
      "1                        1749                    18  ...                  62   \n",
      "2                        3557                     6  ...                  35   \n",
      "3                        3795                     0  ...                  17   \n",
      "4                        4269                    17  ...                   0   \n",
      "\n",
      "   Children_Population  White_Population  Black_Population   \n",
      "0                   67              1502               171  \\\n",
      "1                  122               785              1088   \n",
      "2                   55              2433               983   \n",
      "3                   81              3410               251   \n",
      "4                  134              3323               976   \n",
      "\n",
      "   Limited_English_Proficiency  Households_No_Internet  state  county   tract   \n",
      "0                         1692                      88     01     001  020100  \\\n",
      "1                         1866                     114     01     001  020200   \n",
      "2                         3479                     193     01     001  020300   \n",
      "3                         3585                     121     01     001  020400   \n",
      "4                         4097                      69     01     001  020501   \n",
      "\n",
      "         GEOID  \n",
      "0  01001020100  \n",
      "1  01001020200  \n",
      "2  01001020300  \n",
      "3  01001020400  \n",
      "4  01001020501  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Data saved to 'census_healthcare_accessibility_USA.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://api.census.gov/data/2021/acs/acs5\"\n",
    "API_KEY = \"f29da77399e7891ad61e1aab3a1d9aeaa84c7f20\"\n",
    "\n",
    "# Selected variables to fetch from ACS API\n",
    "VARIABLES = {\n",
    "    \"NAME\": \"Geography\",\n",
    "    \"B11001_001E\": \"Total_Households\",\n",
    "    \"B01003_001E\": \"Total_Population\",\n",
    "    \"B19013_001E\": \"Median_Household_Income\",\n",
    "    \"B17001_002E\": \"Poverty_Population\",\n",
    "    \"B23025_005E\": \"Unemployed_Population\",\n",
    "    \"B19301_001E\": \"Per_Capita_Income\",\n",
    "    \"B22003_002E\": \"SNAP_Recipients\",\n",
    "    \"B27010_001E\": \"Total_Pop_Health_Insurance\",\n",
    "    \"B27010_017E\": \"Uninsured_Population\",\n",
    "    \"B27010_042E\": \"Medicaid_Coverage\",\n",
    "    \"B27010_043E\": \"Medicare_Coverage\",\n",
    "    \"B27010_050E\": \"Private_Insurance_Coverage\",\n",
    "    \"B15003_022E\": \"High_School_Graduates\",\n",
    "    \"B15003_025E\": \"Bachelor_Degree_Holders\",\n",
    "    \"B15003_002E\": \"Less_than_High_School\",\n",
    "    \"B25044_003E\": \"Households_No_Vehicle\",\n",
    "    \"B08303_001E\": \"Commute_Time\",\n",
    "    \"B08301_010E\": \"Public_Transit_Usage\",\n",
    "    \"B25003_003E\": \"Renter_Occupied_Housing\",\n",
    "    \"B25071_001E\": \"Rent_as_Income_Percentage\",\n",
    "    \"B25014_006E\": \"Overcrowded_Housing\",\n",
    "    \"B01001_020E\": \"Elderly_Population\",\n",
    "    \"B01001_003E\": \"Children_Population\",\n",
    "    \"B02001_002E\": \"White_Population\",\n",
    "    \"B02001_003E\": \"Black_Population\",\n",
    "    \"B16004_001E\": \"Limited_English_Proficiency\",\n",
    "    \"B28002_013E\": \"Households_No_Internet\"         \n",
    "}\n",
    "\n",
    "variable_list = \",\".join(VARIABLES.keys())\n",
    "\n",
    "# FIPS codes for all U.S. states (excluding territories)\n",
    "state_fips = [\n",
    "    \"01\", \"02\", \"04\", \"05\", \"06\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "    \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\",\n",
    "    \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"53\",\n",
    "    \"54\", \"55\", \"56\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Fetch data for each state\n",
    "for state in state_fips:   \n",
    "    print(f\"Fetching data for state {state}...\")\n",
    "    \n",
    "    params = {\n",
    "        \"get\": variable_list,\n",
    "        \"for\": \"tract:*\",\n",
    "        \"in\": f\"state:{state}\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        columns = [VARIABLES.get(col, col) for col in data[0]]\n",
    "        df_state = pd.DataFrame(data[1:], columns=columns)\n",
    "        \n",
    "        # Build GEOID for each census tract\n",
    "        if \"county\" in df_state.columns and \"tract\" in df_state.columns:\n",
    "            df_state[\"GEOID\"] = df_state[\"state\"] + df_state[\"county\"] + df_state[\"tract\"]\n",
    "        \n",
    "        all_data.append(df_state)\n",
    "    else:\n",
    "        print(f\"Error fetching data for state {state}: {response.status_code}\")\n",
    "\n",
    "# Combine all states into one DataFrame\n",
    "df_final = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Convert numeric columns to proper types\n",
    "numeric_cols = list(VARIABLES.values())[1:] \n",
    "df_final[numeric_cols] = df_final[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "# Save the data\n",
    "df_final.to_csv(\"socio_economic.csv\", index=False)\n",
    "print(\"Data saved to 'census_healthcare_accessibility_USA.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for state 01...\n",
      "Fetching data for state 02...\n",
      "Fetching data for state 04...\n",
      "Fetching data for state 05...\n",
      "Fetching data for state 06...\n",
      "Fetching data for state 08...\n",
      "Fetching data for state 09...\n",
      "Fetching data for state 10...\n",
      "Fetching data for state 11...\n",
      "Fetching data for state 12...\n",
      "Fetching data for state 13...\n",
      "Fetching data for state 15...\n",
      "Fetching data for state 16...\n",
      "Fetching data for state 17...\n",
      "Fetching data for state 18...\n",
      "Fetching data for state 19...\n",
      "Fetching data for state 20...\n",
      "Fetching data for state 21...\n",
      "Fetching data for state 22...\n",
      "Fetching data for state 23...\n",
      "Fetching data for state 24...\n",
      "Fetching data for state 25...\n",
      "Fetching data for state 26...\n",
      "Fetching data for state 27...\n",
      "Fetching data for state 28...\n",
      "Fetching data for state 29...\n",
      "Fetching data for state 30...\n",
      "Fetching data for state 31...\n",
      "Fetching data for state 32...\n",
      "Fetching data for state 33...\n",
      "Fetching data for state 34...\n",
      "Fetching data for state 35...\n",
      "Fetching data for state 36...\n",
      "Fetching data for state 37...\n",
      "Fetching data for state 38...\n",
      "Fetching data for state 39...\n",
      "Fetching data for state 40...\n",
      "Fetching data for state 41...\n",
      "Fetching data for state 42...\n",
      "Fetching data for state 44...\n",
      "Fetching data for state 45...\n",
      "Fetching data for state 46...\n",
      "Fetching data for state 47...\n",
      "Fetching data for state 48...\n",
      "Fetching data for state 49...\n",
      "Fetching data for state 50...\n",
      "Fetching data for state 51...\n",
      "Fetching data for state 53...\n",
      "Fetching data for state 54...\n",
      "Fetching data for state 55...\n",
      "Fetching data for state 56...\n",
      "                                      Geography  Median_Household_Income   \n",
      "0     Census Tract 201, Autauga County, Alabama                    57399  \\\n",
      "1     Census Tract 202, Autauga County, Alabama                    52176   \n",
      "2     Census Tract 203, Autauga County, Alabama                    63704   \n",
      "3     Census Tract 204, Autauga County, Alabama                    70000   \n",
      "4  Census Tract 205.01, Autauga County, Alabama                    60917   \n",
      "\n",
      "   Poverty_Population  Unemployed_Population  Per_Capita_Income   \n",
      "0                 275                     19            30934.0  \\\n",
      "1                 117                     43            26446.0   \n",
      "2                 614                     45            25683.0   \n",
      "3                 307                     40            47804.0   \n",
      "4                 790                     25            30313.0   \n",
      "\n",
      "   SNAP_Recipients  Total_Pop_Health_Insurance  Uninsured_Population   \n",
      "0              129                        1791                     0  \\\n",
      "1              121                        1749                    18   \n",
      "2              166                        3557                     6   \n",
      "3               39                        3795                     0   \n",
      "4              160                        4269                    17   \n",
      "\n",
      "   Medicaid_Coverage  Medicare_Coverage  ...  White_Population   \n",
      "0                 94                 20  ...              1502  \\\n",
      "1                 82                 18  ...               785   \n",
      "2                377                  6  ...              2433   \n",
      "3                168                  7  ...              3410   \n",
      "4                492                116  ...              3323   \n",
      "\n",
      "   Black_Population  Limited_English_Proficiency  Households_No_Internet   \n",
      "0               171                         1692                      88  \\\n",
      "1              1088                         1866                     114   \n",
      "2               983                         3479                     193   \n",
      "3               251                         3585                     121   \n",
      "4               976                         4097                      69   \n",
      "\n",
      "   Total_Households  Total_Population  state  county   tract        GEOID  \n",
      "0               609              1791     01     001  020100  01001020100  \n",
      "1               600              2010     01     001  020200  01001020200  \n",
      "2              1346              3577     01     001  020300  01001020300  \n",
      "3              1606              3802     01     001  020400  01001020400  \n",
      "4              1789              4381     01     001  020501  01001020501  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Data saved to 'socio_economic.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://api.census.gov/data/2021/acs/acs5\"\n",
    "API_KEY = \"f29da77399e7891ad61e1aab3a1d9aeaa84c7f20\"\n",
    "\n",
    "# Selected variables to fetch from ACS API\n",
    "VARIABLES = {\n",
    "    \"NAME\": \"Geography\",\n",
    "    \"B19013_001E\": \"Median_Household_Income\",\n",
    "    \"B17001_002E\": \"Poverty_Population\",\n",
    "    \"B23025_005E\": \"Unemployed_Population\",\n",
    "    \"B19301_001E\": \"Per_Capita_Income\",\n",
    "    \"B22003_002E\": \"SNAP_Recipients\",\n",
    "    \"B27010_001E\": \"Total_Pop_Health_Insurance\",\n",
    "    \"B27010_017E\": \"Uninsured_Population\",\n",
    "    \"B27010_042E\": \"Medicaid_Coverage\",\n",
    "    \"B27010_043E\": \"Medicare_Coverage\",\n",
    "    \"B27010_050E\": \"Private_Insurance_Coverage\",\n",
    "    \"B15003_022E\": \"High_School_Graduates\",\n",
    "    \"B15003_025E\": \"Bachelor_Degree_Holders\",\n",
    "    \"B15003_002E\": \"Less_than_High_School\",\n",
    "    \"B25044_003E\": \"Households_No_Vehicle\",\n",
    "    \"B08303_001E\": \"Commute_Time\",\n",
    "    \"B08301_010E\": \"Public_Transit_Usage\",\n",
    "    \"B25003_003E\": \"Renter_Occupied_Housing\",\n",
    "    \"B25071_001E\": \"Rent_as_Income_Percentage\",\n",
    "    \"B25014_006E\": \"Overcrowded_Housing\",\n",
    "    \"B01001_020E\": \"Elderly_Population\",\n",
    "    \"B01001_003E\": \"Children_Population\",\n",
    "    \"B02001_002E\": \"White_Population\",\n",
    "    \"B02001_003E\": \"Black_Population\",\n",
    "    \"B16004_001E\": \"Limited_English_Proficiency\",\n",
    "    \"B28002_013E\": \"Households_No_Internet\",\n",
    "    \"B11001_001E\": \"Total_Households\",\n",
    "    \"B01003_001E\": \"Total_Population\"\n",
    "}\n",
    "\n",
    "variable_list = \",\".join(VARIABLES.keys())\n",
    "\n",
    "# FIPS codes for all U.S. states (excluding territories)\n",
    "state_fips = [\n",
    "    \"01\", \"02\", \"04\", \"05\", \"06\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "    \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\",\n",
    "    \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"53\",\n",
    "    \"54\", \"55\", \"56\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Fetch data for each state\n",
    "for state in state_fips:   \n",
    "    print(f\"Fetching data for state {state}...\")\n",
    "    \n",
    "    params = {\n",
    "        \"get\": variable_list,\n",
    "        \"for\": \"tract:*\",\n",
    "        \"in\": f\"state:{state}\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        columns = [VARIABLES.get(col, col) for col in data[0]]\n",
    "        df_state = pd.DataFrame(data[1:], columns=columns)\n",
    "        \n",
    "        # Build GEOID for each census tract\n",
    "        if \"county\" in df_state.columns and \"tract\" in df_state.columns:\n",
    "            df_state[\"GEOID\"] = df_state[\"state\"] + df_state[\"county\"] + df_state[\"tract\"]\n",
    "        \n",
    "        all_data.append(df_state)\n",
    "    else:\n",
    "        print(f\"Error fetching data for state {state}: {response.status_code}\")\n",
    "\n",
    "# Combine all states into one DataFrame\n",
    "df_final = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Convert numeric columns to proper types\n",
    "numeric_cols = list(VARIABLES.values())[1:] \n",
    "df_final[numeric_cols] = df_final[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "# Save the data\n",
    "df_final.to_csv(\"socio_economic.csv\", index=False)\n",
    "print(\"Data saved to 'socio_economic.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data (OSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census boundaries for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Census Tract Boundaries for all U.S. states...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   2%|▏         | 1/51 [00:00<00:14,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 01: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   6%|▌         | 3/51 [00:00<00:10,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 02: 403\n",
      "Failed to download 04: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  10%|▉         | 5/51 [00:01<00:09,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 05: 403\n",
      "Failed to download 06: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  14%|█▎        | 7/51 [00:01<00:06,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 08: 403\n",
      "Failed to download 09: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  20%|█▉        | 10/51 [00:01<00:04,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 10: 403\n",
      "Failed to download 11: 403\n",
      "Failed to download 12: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  24%|██▎       | 12/51 [00:01<00:04,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 13: 403\n",
      "Failed to download 15: 403\n",
      "Failed to download 16: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  31%|███▏      | 16/51 [00:02<00:03,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 17: 403\n",
      "Failed to download 18: 403\n",
      "Failed to download 19: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  37%|███▋      | 19/51 [00:02<00:03, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 20: 403\n",
      "Failed to download 21: 403\n",
      "Failed to download 22: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  41%|████      | 21/51 [00:02<00:02, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 23: 403\n",
      "Failed to download 24: 403\n",
      "Failed to download 25: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  49%|████▉     | 25/51 [00:03<00:02, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 26: 403\n",
      "Failed to download 27: 403\n",
      "Failed to download 28: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  53%|█████▎    | 27/51 [00:03<00:02, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 29: 403\n",
      "Failed to download 30: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  57%|█████▋    | 29/51 [00:03<00:02, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 31: 403\n",
      "Failed to download 32: 403\n",
      "Failed to download 33: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  65%|██████▍   | 33/51 [00:03<00:01, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 34: 403\n",
      "Failed to download 35: 403\n",
      "Failed to download 36: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  69%|██████▊   | 35/51 [00:03<00:01, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 37: 403\n",
      "Failed to download 38: 403\n",
      "Failed to download 39: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  76%|███████▋  | 39/51 [00:04<00:01, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 40: 403\n",
      "Failed to download 41: 403\n",
      "Failed to download 42: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  80%|████████  | 41/51 [00:04<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 44: 403\n",
      "Failed to download 45: 403\n",
      "Failed to download 46: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  84%|████████▍ | 43/51 [00:04<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 47: 403\n",
      "Failed to download 48: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  92%|█████████▏| 47/51 [00:05<00:00, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 49: 403\n",
      "Failed to download 50: 403\n",
      "Failed to download 51: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  96%|█████████▌| 49/51 [00:05<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 53: 403\n",
      "Failed to download 54: 403\n",
      "Failed to download 55: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 51/51 [00:05<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download 56: 403\n",
      "\n",
      "Merging Census Tract Boundaries into a single dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/51 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'census_tracts/cb_2021_01_tract_500k.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     71\u001b[0m     download_census_tracts()\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mmerge_census_tracts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mmerge_census_tracts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m extract_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRACTS_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcb_2021_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_fips\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tract\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(extract_path):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m     53\u001b[0m         zip_ref\u001b[38;5;241m.\u001b[39mextractall(extract_path)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(extract_path):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'census_tracts/cb_2021_01_tract_500k.zip'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of U.S. state FIPS codes (excludes territories)\n",
    "STATE_FIPS_CODES = [\n",
    "    \"01\", \"02\", \"04\", \"05\", \"06\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "    \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\",\n",
    "    \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"53\",\n",
    "    \"54\", \"55\", \"56\"\n",
    "]\n",
    "\n",
    "# Directory to store downloaded ZIP files\n",
    "TRACTS_DIR = \"census_tracts\"\n",
    "os.makedirs(TRACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Download census tract shapefiles for all states\n",
    "def download_census_tracts():\n",
    "    print(\"Downloading Census Tract Boundaries for all U.S. states...\\n\")\n",
    "\n",
    "    for state_fips in tqdm(STATE_FIPS_CODES, desc=\"Downloading\"):\n",
    "        url = f\"https://www2.census.gov/geo/tiger/GENZ2021/shp/cb_2021_{state_fips}_tract_500k.zip\"\n",
    "        zip_path = os.path.join(TRACTS_DIR, f\"cb_2021_{state_fips}_tract_500k.zip\")\n",
    "\n",
    "        if os.path.exists(zip_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(zip_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(1024):\n",
    "                        f.write(chunk)\n",
    "            else:\n",
    "                print(f\"Failed to download {state_fips}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {state_fips}: {e}\")\n",
    "\n",
    "# Unzip and combine all tract shapefiles into one GeoDataFrame\n",
    "def merge_census_tracts():\n",
    "    print(\"\\nMerging Census Tract Boundaries into a single dataset...\\n\")\n",
    "    all_tracts = []\n",
    "\n",
    "    for state_fips in tqdm(STATE_FIPS_CODES, desc=\"Processing\"):\n",
    "        zip_path = os.path.join(TRACTS_DIR, f\"cb_2021_{state_fips}_tract_500k.zip\")\n",
    "        extract_path = os.path.join(TRACTS_DIR, f\"cb_2021_{state_fips}_tract\")\n",
    "\n",
    "        if not os.path.exists(extract_path):\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(extract_path)\n",
    "\n",
    "        for file in os.listdir(extract_path):\n",
    "            if file.endswith(\".shp\"):\n",
    "                shp_path = os.path.join(extract_path, file)\n",
    "                try:\n",
    "                    gdf = gpd.read_file(shp_path)\n",
    "                    all_tracts.append(gdf)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {shp_path}: {e}\")\n",
    "\n",
    "    merged_gdf = gpd.GeoDataFrame(pd.concat(all_tracts, ignore_index=True))\n",
    "    merged_gdf = merged_gdf.to_crs(epsg=4326)\n",
    "    merged_gdf.to_file(\"census_tracts_USA.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "# Run download and merge steps\n",
    "if __name__ == \"__main__\":\n",
    "    download_census_tracts()\n",
    "    merge_census_tracts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load census tract boundaries\n",
    "census_tracts_gdf = gpd.read_file(\"census_tracts_USA.geojson\")\n",
    "\n",
    "# Reproject to lat/lon\n",
    "census_tracts_gdf = census_tracts_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Calculate centroid of each tract\n",
    "census_tracts_gdf[\"centroid\"] = census_tracts_gdf.geometry.centroid\n",
    "\n",
    "# Create GeoDataFrame using centroids\n",
    "centroids_gdf = gpd.GeoDataFrame(\n",
    "    census_tracts_gdf[[\"GEOID\", \"centroid\"]],\n",
    "    geometry=\"centroid\",\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Export to GeoJSON\n",
    "centroids_gdf.to_file(\"census_tract_centroids.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthcare facilities USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Handler to extract nodes with healthcare-related tags\n",
    "class HealthcareHandler(osmium.SimpleHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nodes = []\n",
    "\n",
    "    def node(self, n):\n",
    "        if \"amenity\" in n.tags:\n",
    "            self.nodes.append({\n",
    "                \"id\": n.id,\n",
    "                \"name\": n.tags.get(\"name\", \"Unknown\"),\n",
    "                \"amenity\": n.tags[\"amenity\"],\n",
    "                \"lat\": n.location.lat,\n",
    "                \"lon\": n.location.lon\n",
    "            })\n",
    "\n",
    "# Run the handler on the .osm.pbf file\n",
    "handler = HealthcareHandler()\n",
    "handler.apply_file(\"healthcare.osm.pbf\")\n",
    "\n",
    "# Convert extracted points to a GeoDataFrame\n",
    "healthcare_gdf = gpd.GeoDataFrame(\n",
    "    handler.nodes,\n",
    "    geometry=gpd.points_from_xy([n[\"lon\"] for n in handler.nodes], [n[\"lat\"] for n in handler.nodes])\n",
    ")\n",
    "\n",
    "# Set the CRS to WGS84\n",
    "healthcare_gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Export to GeoJSON\n",
    "healthcare_gdf.to_file(\"healthcare_facilities_USA.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Facilities by Category for Each Census Centroid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Load healthcare and census data\n",
    "healthcare_fp = \"healthcare_facilities_USA.geojson\"\n",
    "census_centroids_fp = \"census_tract_centroids.geojson\"\n",
    "healthcare = gpd.read_file(healthcare_fp)\n",
    "census = gpd.read_file(census_centroids_fp)\n",
    "\n",
    "# Set both to the same geographic coordinate system\n",
    "healthcare = healthcare.to_crs(epsg=4326)\n",
    "census = census.to_crs(epsg=4326)\n",
    "\n",
    "# Reproject to meters for accurate distance measurements\n",
    "healthcare_proj = healthcare.to_crs(epsg=3857)\n",
    "census_proj = census.to_crs(epsg=3857)\n",
    "\n",
    "# Create buffer zones (5 km) around each census centroid\n",
    "buffer_distance = 5000  \n",
    "census_proj[\"buffer\"] = census_proj.geometry.buffer(buffer_distance)\n",
    "\n",
    "# Use buffers to find nearby healthcare facilities\n",
    "census_buffers = census_proj.set_geometry(\"buffer\")\n",
    "joined = gpd.sjoin(healthcare_proj, census_buffers, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Count facilities by type for each census area\n",
    "counts = joined.groupby([\"index_right\", \"amenity\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Convert counts into columns by facility type\n",
    "pivot_counts = counts.pivot(index=\"index_right\", columns=\"amenity\", values=\"count\").fillna(0)\n",
    "\n",
    "# Attach the counts back to original census data\n",
    "census = census.set_index(census.index)\n",
    "census_counts = census.join(pivot_counts, how=\"left\").fillna(0)\n",
    "census_counts = census_counts.reset_index(drop=True)\n",
    "print(census_counts.head())\n",
    "\n",
    "# Save the final result\n",
    "output_fp = \"census_with_healthcare_counts.geojson\"\n",
    "census_counts.to_file(output_fp, driver=\"GeoJSON\")\n",
    "print(f\"Saved the counts to {output_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Professional Shortage Areas (HPSA)\n",
    "\n",
    "Source: https://data.hrsa.gov/data/download\n",
    "\n",
    "Look into shortage area section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HPSA Name', 'HPSA ID', 'Designation Type', 'HPSA Discipline Class',\n",
      "       'HPSA Score', 'PC MCTA Score', 'Primary State Abbreviation',\n",
      "       'HPSA Status', 'HPSA Designation Date',\n",
      "       'HPSA Designation Last Update Date', 'Metropolitan Indicator',\n",
      "       'HPSA Geography Identification Number', 'HPSA Degree of Shortage',\n",
      "       'Withdrawn Date', 'HPSA FTE', 'HPSA Designation Population',\n",
      "       '% of Population Below 100% Poverty', 'HPSA Formal Ratio',\n",
      "       'HPSA Population Type', 'Rural Status', 'Longitude', 'Latitude',\n",
      "       'BHCMIS Organization Identification Number', 'Break in Designation',\n",
      "       'Common County Name', 'Common Postal Code', 'Common Region Name',\n",
      "       'Common State Abbreviation', 'Common State County FIPS Code',\n",
      "       'Common State FIPS Code', 'Common State Name', 'County Equivalent Name',\n",
      "       'County or County Equivalent Federal Information Processing Standard Code',\n",
      "       'Discipline Class Number', 'HPSA Address', 'HPSA City',\n",
      "       'HPSA Component Name', 'HPSA Component Source Identification Number',\n",
      "       'HPSA Component State Abbreviation', 'HPSA Component Type Code',\n",
      "       'HPSA Component Type Description',\n",
      "       'HPSA Designation Population Type Description',\n",
      "       'HPSA Estimated Served Population',\n",
      "       'HPSA Estimated Underserved Population',\n",
      "       'HPSA Metropolitan Indicator Code', 'HPSA Population Type Code',\n",
      "       'HPSA Postal Code', 'HPSA Provider Ratio Goal',\n",
      "       'HPSA Resident Civilian Population', 'HPSA Shortage',\n",
      "       'HPSA Status Code', 'HPSA Type Code', 'HPSA Withdrawn Date String',\n",
      "       'Primary State FIPS Code', 'Primary State Name', 'Provider Type',\n",
      "       'Rural Status Code', 'State Abbreviation',\n",
      "       'State and County Federal Information Processing Standard Code',\n",
      "       'State FIPS Code', 'State Name',\n",
      "       'U.S. - Mexico Border 100 Kilometer Indicator',\n",
      "       'U.S. - Mexico Border County Indicator',\n",
      "       'Data Warehouse Record Create Date',\n",
      "       'Data Warehouse Record Create Date Text', 'Unnamed: 65'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"BCD_HPSA_FCT_DET_PC.csv\")\n",
    "\n",
    "# Print columns to verify exact names\n",
    "print(df.columns)\n",
    "\n",
    "# Define columns to keep\n",
    "keep_cols = [\n",
    "    \"HPSA Name\",\n",
    "    \"HPSA ID\",\n",
    "    \"HPSA Score\",\n",
    "    'HPSA Designation Date',\n",
    "    \"HPSA Status Code\",\n",
    "    \"HPSA Type Code\",\n",
    "    \"HPSA Formal Ratio\",\n",
    "    \"Common State County FIPS Code\",\n",
    "    \"State FIPS Code\",\n",
    "    \"State Name\"\n",
    "]\n",
    "\n",
    "# Filter the DataFrame\n",
    "keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "df_filtered = df[keep_cols]\n",
    "df_filtered.to_csv(\"HPSA.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
